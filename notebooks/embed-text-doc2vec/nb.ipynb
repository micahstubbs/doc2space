{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embed-text-doc2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on https://medium.com/@mishra.thedeepak/doc2vec-simple-implementation-example-df2afbbfbad5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first, let's install some dependencies. a guide to doing this: https://jakevdp.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching package metadata .........\n",
      "Solving package specifications: .\n",
      "\n",
      "# All requested packages already installed.\n",
      "# packages in environment at /Users/m/anaconda3/envs/parse-html:\n",
      "#\n",
      "gensim                    2.3.0               np113py36_0  \n",
      "nltk                      3.2.4                    py36_0  \n"
     ]
    }
   ],
   "source": [
    "# Install a conda package in the current Jupyter kernel\n",
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} gensim nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the dependencies\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s prepare data for training our doc2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../data/'\n",
    "\n",
    "# our list of documents\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "txt_files = glob.glob(f\"{data_dir}/*.txt\")\n",
    "print(len(txt_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141\n"
     ]
    }
   ],
   "source": [
    "for file in txt_files:\n",
    "    with open(file, 'r', encoding=\"utf-8\") as file:\n",
    "        currentText = file.read()\n",
    "        data.append(currentText)\n",
    "        file.close()\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bubbleworld\n",
      "A New Visual Information Retrieval Technique\n",
      "Christopher Van Berendonck\n",
      "\n",
      "Timothy Jacobs\n",
      "\n",
      "Chris.Vanberendonck@defence.gov.au\n",
      "\n",
      "Timothy.Jacobs@afit.edu\n",
      "\n",
      "Air Force Institute of Technology\n",
      "Wright-Patterson Air Force Base\n",
      "Ohio 45433 USA\n",
      "\n",
      "Abstract\n",
      "Visualisation has significant advantages over traditional textual\n",
      "lists for improving cognition in information retrieval. To realise\n",
      "these advantages, we identify a set of cognitive principles and\n",
      "usage patterns for information retrieval. We apply these\n",
      "principles and patterns to the design of a prototype visual\n",
      "information retrieval system, Bubbleworld. In Bubbleworld, we\n",
      "apply a variety of visual techniques that successfully transform\n",
      "the internal mental representations of the information retrieval\n",
      "problem to an efficient external view and, through visual cues,\n",
      "provide cognitive amplification at key stages of the information\n",
      "retrieval process. We enhance the knowledge acquisition\n",
      "process by providing query refinement and interaction\n",
      "te\n"
     ]
    }
   ],
   "source": [
    "from random import randrange\n",
    "random_index = randrange(len(data)-1)\n",
    "\n",
    "# print the first 1000 characters of a random document from our corpus\n",
    "print(data[random_index][0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), \n",
    "    tags=[str(i)]) for i, _d in enumerate(data)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a list of four sentences as training data. Now I have tagged the data and its ready for training. Lets start training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 100\n",
    "vec_size = 20\n",
    "alpha = 0.025\n",
    "model = Doc2Vec(size=vec_size,\n",
    "                alpha=alpha,\n",
    "                min_alpha=0.00025,\n",
    "                min_count=1,\n",
    "                dm=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epochs):\n",
    "    print ('iteration {0}'.format(epoch))\n",
    "    model.train(tagged_data,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=model.iter)\n",
    "    # decrease the learning rate\n",
    "    model.alpha -= 0.002\n",
    "    # fix the learning rate, no decay\n",
    "    model.min_alpha = model.alpha\n",
    "    \n",
    "model.save(\"d2v.model\")\n",
    "print(\"Model d2v.model Saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: dm defines the training algorithm. If dm=1 means ‘distributed memory’ (PV-DM) and dm =0 means ‘distributed bag of words’ (PV-DBOW). Distributed Memory model preserves the word order in a document whereas Distributed Bag of words just uses the bag of words approach, which doesn’t preserve any word order.\n",
    "\n",
    "So we have saved the model and it’s ready for implementation. Lets play with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1_infer [-0.04641611  0.06686842 -0.16633473 -0.03932161 -0.21618296 -0.17176464\n",
      " -0.00281937 -0.05164452  0.06644855  0.1896757   0.07190223  0.14555858\n",
      "  0.08542146  0.0769899  -0.16427462 -0.05566296 -0.02271955 -0.00445893\n",
      " -0.13367924 -0.03909039]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "model= Doc2Vec.load(\"d2v.model\")\n",
    "\n",
    "#to find the vector of a document which is not in the training data\n",
    "test_data = word_tokenize(\"I love chatbots\".lower())\n",
    "v1 = model.infer_vector(test_data)\n",
    "print(\"V1_infer\", v1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('3', 0.9997655153274536), ('0', 0.9997013211250305), ('2', 0.9996600151062012)]\n"
     ]
    }
   ],
   "source": [
    "# to find most similar doc using tags\n",
    "similar_doc = model.docvecs.most_similar('1')\n",
    "print(similar_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.87429625 -0.9460634   2.01648474  0.3264634   2.64323592  2.13081336\n",
      " -0.04919869  0.78078324 -1.01873863 -2.38981891 -0.93454051 -1.7502445\n",
      " -1.24811769 -0.83962041  2.1012814   0.74003488  0.29993519  0.08836075\n",
      "  1.56579375  0.39734492]\n"
     ]
    }
   ],
   "source": [
    "# to find vector of doc in training data using tags\n",
    "# or in other words printing the vector of the document \n",
    "# at index 1 in the training data\n",
    "print(model.docvecs['1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 - parse-html",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
